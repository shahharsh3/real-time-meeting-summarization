{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f1ebaa-f572-46a3-b876-439d20e65a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/admed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/admed/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import pipeline\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63854f3-e7c2-41ea-92d9-2d6a4ee7ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'corpus/'\n",
    "path='corpus/data-processing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8294d71d-3b4f-48df-981b-38da4673f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open(root_path + 'train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(root_path + 'test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "with open(root_path + 'val.json', 'r', encoding='utf-8') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "eval_df = pd.DataFrame(eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69342ffd-1eb3-4d43-a192-c5049a5ee284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue: \n",
      "Perry: have you thought about holiday yet?\n",
      "Marlow: Asia?\n",
      "Perry: you mean in July or August?\n",
      "Marlow: w/janet we thought about September it's cheaper i guess\n",
      "Janet: yeah but we need to check the weather and everything\n",
      "Forster: Cloete wanted to go to the mountains so i guess that's my plan\n",
      "Perry: frankly we have no idea. went to seaside last year\n",
      "Marlow: Asia could be the place 2go. Janet would be cool yeah?\n",
      "Janet: sure thing. Would be gr8 2go 2gether\n",
      "Perry: dunno if we can afford. Need to talk to Nina\n",
      "Janet: why not meet 2nite over beer and talk?\n",
      "Perry: super but not 2day no. cinema :):)\n",
      "Janet: oh I forgot you won the tickets right?\n",
      "Perry: yeah but we could meet 2moro evening if ur free\n",
      "Janet: do we have plans Marlow? \n",
      "Marlow: no i dont think so\n",
      "Forster: could we come over too\n",
      "Perry: yeah fantastic. byob tho\n",
      "Forster: sure thing 8 pm is fine?\n",
      "Perry: perfect for me\n",
      "Janet: gr8 for us. we can visit pa first\n",
      "Marlow: fine by me. let's do it guys!\n",
      "---------------\n",
      "Human Summary: \n",
      "Perry, Marlow, Janet and Forster discuss their holiday plans. Marlow would like to go to Asia, others will think if they can join. The friends will meet tomorrow at 8 pm to discuss that. \n",
      "t5-small summary:\n",
      "Marlow and Forster are planning a holiday in Asia. They are going to meet at 8 pm. They will go to pa first.\n",
      "flan-t5-base summary:\n",
      "Marlow, Janet, Forster and Forster are planning a holiday in Asia in September. They will meet tomorrow at 8 pm at the cinema.\n",
      "bart-base summary:\n",
      "Perry, Marlow and Forster are thinking about holiday in Asia in July or August. Forster wants to go to the mountains. Marlow will come over at 8 pm.\n"
     ]
    }
   ],
   "source": [
    "# load all the model and tokenizer from huggingface hub with pipeline\n",
    "t5_small_summarizer = pipeline(\"summarization\", model=path+'t5-small')\n",
    "flan_t5_base_summarizer = pipeline(\"summarization\", model=path+'flan-t5-base')\n",
    "bart_base_summarizer = pipeline(\"summarization\", model=path+'bart-base')\n",
    "\n",
    "# select a random test sample\n",
    "sample = test_df.iloc[randrange(len(test_df))]\n",
    "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "print(f\"Human Summary: \\n{sample['summary']}\")\n",
    "# summarize dialogue\n",
    "t5_small_res = t5_small_summarizer(sample[\"dialogue\"])          #max_length=200, min_length=20 is set by default\n",
    "flan_t5_base = flan_t5_base_summarizer(sample[\"dialogue\"])      #max_length=200, min_length=20 is set by default\n",
    "bart_base = bart_base_summarizer(sample[\"dialogue\"], max_length=200, min_length=20, do_sample=False)\n",
    "\n",
    "print(f\"t5-small summary:\\n{t5_small_res[0]['summary_text']}\")\n",
    "print(f\"flan-t5-base summary:\\n{flan_t5_base[0]['summary_text']}\")\n",
    "print(f\"bart-base summary:\\n{bart_base[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb5ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
