{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f1ebaa-f572-46a3-b876-439d20e65a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/admed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/admed/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import pipeline\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63854f3-e7c2-41ea-92d9-2d6a4ee7ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'corpus/'\n",
    "path='corpus/data-processing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8294d71d-3b4f-48df-981b-38da4673f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open(root_path + 'train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(root_path + 'test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "with open(root_path + 'val.json', 'r', encoding='utf-8') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "eval_df = pd.DataFrame(eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69342ffd-1eb3-4d43-a192-c5049a5ee284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "Your max_length is set to 200, but your input_length is only 61. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Summary: \n",
      "Paul can couch the game on Saturday as Matthew hasn't found anyone to do that yet. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 62. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\n",
      "Your max_length is set to 200, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-small summary:\n",
      "Paul hasn't found anyone to couch the game on Saturday. He will do it if he needs to. Paul will see Matthew on Saturday as he has changed his plans.\n",
      "\n",
      "flan-t5-base summary:\n",
      "Paul will couch the game on Saturday. Matthew is still looking for someone to do it. Paul's plans changed so he can do it if Matthew needs it.\n",
      "\n",
      "bart-base summary:\n",
      "Paul is looking for someone to couch the game on Saturday. Matthew will do it. \n"
     ]
    }
   ],
   "source": [
    "# load all the model and tokenizer from huggingface hub with pipeline\n",
    "t5_small_summarizer = pipeline(\"summarization\", model=path+'t5-small')\n",
    "flan_t5_base_summarizer = pipeline(\"summarization\", model=path+'flan-t5-base')\n",
    "bart_base_summarizer = pipeline(\"summarization\", model=path+'bart-base')\n",
    "\n",
    "# select a random test sample\n",
    "sample = test_df.iloc[randrange(len(test_df))]\n",
    "# print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "print(f\"Human Summary: \\n{sample['summary']}\")\n",
    "# summarize dialogue\n",
    "t5_small_res = t5_small_summarizer(sample[\"dialogue\"])          #max_length=200, min_length=20 is set by default\n",
    "flan_t5_base = flan_t5_base_summarizer(sample[\"dialogue\"])      #max_length=200, min_length=20 is set by default\n",
    "bart_base = bart_base_summarizer(sample[\"dialogue\"], max_length=200, min_length=20, do_sample=False)\n",
    "\n",
    "print(f\"t5-small summary:\\n{t5_small_res[0]['summary_text']}\\n\")\n",
    "print(f\"flan-t5-base summary:\\n{flan_t5_base[0]['summary_text']}\\n\")\n",
    "print(f\"bart-base summary:\\n{bart_base[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69177879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
