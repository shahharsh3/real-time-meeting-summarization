{
  "best_metric": 0.08397004008293152,
  "best_model_checkpoint": "corpus/data-processing//bart/results/checkpoint-1842",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1842,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 112.9877700805664,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 16.2564,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 125.50544738769531,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 15.325,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 30.738201141357422,
      "learning_rate": 3e-06,
      "loss": 14.2017,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 24.406394958496094,
      "learning_rate": 4.000000000000001e-06,
      "loss": 13.0654,
      "step": 40
    },
    {
      "epoch": 0.03,
      "grad_norm": 24.64297103881836,
      "learning_rate": 5e-06,
      "loss": 12.224,
      "step": 50
    },
    {
      "epoch": 0.03,
      "grad_norm": 32.94853591918945,
      "learning_rate": 6e-06,
      "loss": 11.3836,
      "step": 60
    },
    {
      "epoch": 0.04,
      "grad_norm": 94.65069580078125,
      "learning_rate": 7.000000000000001e-06,
      "loss": 10.3259,
      "step": 70
    },
    {
      "epoch": 0.04,
      "grad_norm": 51.85152816772461,
      "learning_rate": 8.000000000000001e-06,
      "loss": 8.4716,
      "step": 80
    },
    {
      "epoch": 0.05,
      "grad_norm": 52.673484802246094,
      "learning_rate": 9e-06,
      "loss": 6.6491,
      "step": 90
    },
    {
      "epoch": 0.05,
      "grad_norm": 50.56863021850586,
      "learning_rate": 1e-05,
      "loss": 5.6499,
      "step": 100
    },
    {
      "epoch": 0.06,
      "grad_norm": 50.288509368896484,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 5.0,
      "step": 110
    },
    {
      "epoch": 0.07,
      "grad_norm": 49.5418815612793,
      "learning_rate": 1.2e-05,
      "loss": 4.494,
      "step": 120
    },
    {
      "epoch": 0.07,
      "grad_norm": 49.77305221557617,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 4.0663,
      "step": 130
    },
    {
      "epoch": 0.08,
      "grad_norm": 49.39019775390625,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 3.6457,
      "step": 140
    },
    {
      "epoch": 0.08,
      "grad_norm": 48.618751525878906,
      "learning_rate": 1.5e-05,
      "loss": 3.2668,
      "step": 150
    },
    {
      "epoch": 0.09,
      "grad_norm": 48.17124557495117,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.8629,
      "step": 160
    },
    {
      "epoch": 0.09,
      "grad_norm": 46.663551330566406,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 2.4479,
      "step": 170
    },
    {
      "epoch": 0.1,
      "grad_norm": 43.38494873046875,
      "learning_rate": 1.8e-05,
      "loss": 2.0569,
      "step": 180
    },
    {
      "epoch": 0.1,
      "grad_norm": 39.36716079711914,
      "learning_rate": 1.9e-05,
      "loss": 1.6757,
      "step": 190
    },
    {
      "epoch": 0.11,
      "grad_norm": 33.48127365112305,
      "learning_rate": 2e-05,
      "loss": 1.2958,
      "step": 200
    },
    {
      "epoch": 0.11,
      "grad_norm": 26.98048973083496,
      "learning_rate": 2.1e-05,
      "loss": 0.9793,
      "step": 210
    },
    {
      "epoch": 0.12,
      "grad_norm": 19.75365447998047,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.684,
      "step": 220
    },
    {
      "epoch": 0.12,
      "grad_norm": 13.119117736816406,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.4873,
      "step": 230
    },
    {
      "epoch": 0.13,
      "grad_norm": 7.872811317443848,
      "learning_rate": 2.4e-05,
      "loss": 0.325,
      "step": 240
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.410354137420654,
      "learning_rate": 2.5e-05,
      "loss": 0.2348,
      "step": 250
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.394601345062256,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.1953,
      "step": 260
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2865742444992065,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.145,
      "step": 270
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7844545841217041,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.1396,
      "step": 280
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5991266369819641,
      "learning_rate": 2.9e-05,
      "loss": 0.1345,
      "step": 290
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6246963739395142,
      "learning_rate": 3e-05,
      "loss": 0.1143,
      "step": 300
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4779425859451294,
      "learning_rate": 3.1e-05,
      "loss": 0.1194,
      "step": 310
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5678162574768066,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.1186,
      "step": 320
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4713185429573059,
      "learning_rate": 3.3e-05,
      "loss": 0.1153,
      "step": 330
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.41734805703163147,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.1253,
      "step": 340
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.37070372700691223,
      "learning_rate": 3.5e-05,
      "loss": 0.1026,
      "step": 350
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4757091999053955,
      "learning_rate": 3.6e-05,
      "loss": 0.1074,
      "step": 360
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.623488187789917,
      "learning_rate": 3.7e-05,
      "loss": 0.1026,
      "step": 370
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5311533808708191,
      "learning_rate": 3.8e-05,
      "loss": 0.117,
      "step": 380
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.43271729350090027,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.1057,
      "step": 390
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.46109822392463684,
      "learning_rate": 4e-05,
      "loss": 0.1092,
      "step": 400
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4422503709793091,
      "learning_rate": 4.1e-05,
      "loss": 0.1314,
      "step": 410
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.45385968685150146,
      "learning_rate": 4.2e-05,
      "loss": 0.1003,
      "step": 420
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4785659611225128,
      "learning_rate": 4.3e-05,
      "loss": 0.1084,
      "step": 430
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.43388721346855164,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.109,
      "step": 440
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.45045986771583557,
      "learning_rate": 4.5e-05,
      "loss": 0.1128,
      "step": 450
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.418828547000885,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.1182,
      "step": 460
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.402822881937027,
      "learning_rate": 4.7e-05,
      "loss": 0.1107,
      "step": 470
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.43401432037353516,
      "learning_rate": 4.8e-05,
      "loss": 0.1088,
      "step": 480
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5170685648918152,
      "learning_rate": 4.9e-05,
      "loss": 0.1162,
      "step": 490
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.45036986470222473,
      "learning_rate": 5e-05,
      "loss": 0.1133,
      "step": 500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.35131576657295227,
      "learning_rate": 4.96274217585693e-05,
      "loss": 0.1098,
      "step": 510
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4430077075958252,
      "learning_rate": 4.92548435171386e-05,
      "loss": 0.1153,
      "step": 520
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.33281370997428894,
      "learning_rate": 4.88822652757079e-05,
      "loss": 0.1051,
      "step": 530
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.43320444226264954,
      "learning_rate": 4.85096870342772e-05,
      "loss": 0.098,
      "step": 540
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.45980849862098694,
      "learning_rate": 4.81371087928465e-05,
      "loss": 0.1017,
      "step": 550
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.458633154630661,
      "learning_rate": 4.77645305514158e-05,
      "loss": 0.1127,
      "step": 560
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.34768199920654297,
      "learning_rate": 4.73919523099851e-05,
      "loss": 0.1293,
      "step": 570
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.44236594438552856,
      "learning_rate": 4.70193740685544e-05,
      "loss": 0.1145,
      "step": 580
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.42674094438552856,
      "learning_rate": 4.66467958271237e-05,
      "loss": 0.097,
      "step": 590
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.46119046211242676,
      "learning_rate": 4.6274217585693e-05,
      "loss": 0.1083,
      "step": 600
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.47177717089653015,
      "learning_rate": 4.59016393442623e-05,
      "loss": 0.1171,
      "step": 610
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.4615018367767334,
      "learning_rate": 4.55290611028316e-05,
      "loss": 0.1133,
      "step": 620
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.43681156635284424,
      "learning_rate": 4.5156482861400894e-05,
      "loss": 0.1024,
      "step": 630
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7820340394973755,
      "learning_rate": 4.4783904619970195e-05,
      "loss": 0.1155,
      "step": 640
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4302312135696411,
      "learning_rate": 4.4411326378539496e-05,
      "loss": 0.1083,
      "step": 650
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3333154022693634,
      "learning_rate": 4.403874813710879e-05,
      "loss": 0.1056,
      "step": 660
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.44020962715148926,
      "learning_rate": 4.366616989567809e-05,
      "loss": 0.1091,
      "step": 670
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.38731473684310913,
      "learning_rate": 4.32935916542474e-05,
      "loss": 0.106,
      "step": 680
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.45405706763267517,
      "learning_rate": 4.29210134128167e-05,
      "loss": 0.1145,
      "step": 690
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3443792462348938,
      "learning_rate": 4.2548435171385993e-05,
      "loss": 0.1041,
      "step": 700
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3648277521133423,
      "learning_rate": 4.2175856929955294e-05,
      "loss": 0.0983,
      "step": 710
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.30426350235939026,
      "learning_rate": 4.1803278688524595e-05,
      "loss": 0.1003,
      "step": 720
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3717535436153412,
      "learning_rate": 4.143070044709389e-05,
      "loss": 0.1043,
      "step": 730
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3774532377719879,
      "learning_rate": 4.105812220566319e-05,
      "loss": 0.0899,
      "step": 740
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.2939722537994385,
      "learning_rate": 4.068554396423249e-05,
      "loss": 0.0971,
      "step": 750
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.3736856281757355,
      "learning_rate": 4.0312965722801785e-05,
      "loss": 0.1063,
      "step": 760
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.27871233224868774,
      "learning_rate": 3.9940387481371086e-05,
      "loss": 0.1179,
      "step": 770
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.375395268201828,
      "learning_rate": 3.956780923994039e-05,
      "loss": 0.1106,
      "step": 780
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.41350847482681274,
      "learning_rate": 3.919523099850969e-05,
      "loss": 0.1135,
      "step": 790
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3092294931411743,
      "learning_rate": 3.882265275707899e-05,
      "loss": 0.1025,
      "step": 800
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5542813539505005,
      "learning_rate": 3.845007451564829e-05,
      "loss": 0.1,
      "step": 810
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.41811487078666687,
      "learning_rate": 3.807749627421759e-05,
      "loss": 0.1115,
      "step": 820
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.4521874785423279,
      "learning_rate": 3.7704918032786885e-05,
      "loss": 0.1078,
      "step": 830
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3147076666355133,
      "learning_rate": 3.7332339791356186e-05,
      "loss": 0.1011,
      "step": 840
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.43757355213165283,
      "learning_rate": 3.695976154992549e-05,
      "loss": 0.0973,
      "step": 850
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.38172805309295654,
      "learning_rate": 3.658718330849479e-05,
      "loss": 0.1053,
      "step": 860
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4330780506134033,
      "learning_rate": 3.621460506706408e-05,
      "loss": 0.1119,
      "step": 870
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.42285093665122986,
      "learning_rate": 3.584202682563338e-05,
      "loss": 0.1025,
      "step": 880
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.39286521077156067,
      "learning_rate": 3.5469448584202684e-05,
      "loss": 0.0973,
      "step": 890
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.34018585085868835,
      "learning_rate": 3.5096870342771985e-05,
      "loss": 0.0855,
      "step": 900
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3992241322994232,
      "learning_rate": 3.4724292101341285e-05,
      "loss": 0.1024,
      "step": 910
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.46443453431129456,
      "learning_rate": 3.4351713859910586e-05,
      "loss": 0.0984,
      "step": 920
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.49242934584617615,
      "learning_rate": 3.397913561847989e-05,
      "loss": 0.0967,
      "step": 930
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4346831738948822,
      "learning_rate": 3.360655737704918e-05,
      "loss": 0.1115,
      "step": 940
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3595479130744934,
      "learning_rate": 3.323397913561848e-05,
      "loss": 0.107,
      "step": 950
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.33859682083129883,
      "learning_rate": 3.286140089418778e-05,
      "loss": 0.1053,
      "step": 960
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.4633232057094574,
      "learning_rate": 3.248882265275708e-05,
      "loss": 0.1065,
      "step": 970
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.41311341524124146,
      "learning_rate": 3.211624441132638e-05,
      "loss": 0.0974,
      "step": 980
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4626680314540863,
      "learning_rate": 3.174366616989568e-05,
      "loss": 0.1025,
      "step": 990
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.49677860736846924,
      "learning_rate": 3.137108792846498e-05,
      "loss": 0.0982,
      "step": 1000
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.28715887665748596,
      "learning_rate": 3.0998509687034274e-05,
      "loss": 0.1019,
      "step": 1010
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5077965259552002,
      "learning_rate": 3.0625931445603575e-05,
      "loss": 0.1063,
      "step": 1020
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.44841888546943665,
      "learning_rate": 3.025335320417288e-05,
      "loss": 0.0894,
      "step": 1030
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4256640672683716,
      "learning_rate": 2.9880774962742174e-05,
      "loss": 0.1075,
      "step": 1040
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.46938684582710266,
      "learning_rate": 2.9508196721311478e-05,
      "loss": 0.1113,
      "step": 1050
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.33361437916755676,
      "learning_rate": 2.913561847988078e-05,
      "loss": 0.0934,
      "step": 1060
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.42365604639053345,
      "learning_rate": 2.876304023845008e-05,
      "loss": 0.0861,
      "step": 1070
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3927784562110901,
      "learning_rate": 2.8390461997019374e-05,
      "loss": 0.0984,
      "step": 1080
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3450520634651184,
      "learning_rate": 2.8017883755588675e-05,
      "loss": 0.1076,
      "step": 1090
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3213306963443756,
      "learning_rate": 2.7645305514157976e-05,
      "loss": 0.0996,
      "step": 1100
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.49149850010871887,
      "learning_rate": 2.7272727272727273e-05,
      "loss": 0.1088,
      "step": 1110
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4134395122528076,
      "learning_rate": 2.6900149031296574e-05,
      "loss": 0.0971,
      "step": 1120
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.38598039746284485,
      "learning_rate": 2.6527570789865875e-05,
      "loss": 0.1111,
      "step": 1130
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4021414816379547,
      "learning_rate": 2.615499254843517e-05,
      "loss": 0.1061,
      "step": 1140
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.45165589451789856,
      "learning_rate": 2.578241430700447e-05,
      "loss": 0.1119,
      "step": 1150
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.41956841945648193,
      "learning_rate": 2.540983606557377e-05,
      "loss": 0.1052,
      "step": 1160
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.34922099113464355,
      "learning_rate": 2.5037257824143072e-05,
      "loss": 0.1032,
      "step": 1170
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.32448166608810425,
      "learning_rate": 2.4664679582712373e-05,
      "loss": 0.0826,
      "step": 1180
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.39680546522140503,
      "learning_rate": 2.429210134128167e-05,
      "loss": 0.0983,
      "step": 1190
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.33754512667655945,
      "learning_rate": 2.391952309985097e-05,
      "loss": 0.1133,
      "step": 1200
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.29888200759887695,
      "learning_rate": 2.354694485842027e-05,
      "loss": 0.1007,
      "step": 1210
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.4082469046115875,
      "learning_rate": 2.317436661698957e-05,
      "loss": 0.0915,
      "step": 1220
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.30322882533073425,
      "learning_rate": 2.280178837555887e-05,
      "loss": 0.1129,
      "step": 1230
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3738328516483307,
      "learning_rate": 2.2429210134128168e-05,
      "loss": 0.0978,
      "step": 1240
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3091849386692047,
      "learning_rate": 2.205663189269747e-05,
      "loss": 0.123,
      "step": 1250
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.44844740629196167,
      "learning_rate": 2.1684053651266766e-05,
      "loss": 0.0968,
      "step": 1260
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.317928671836853,
      "learning_rate": 2.1311475409836064e-05,
      "loss": 0.0852,
      "step": 1270
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3128806948661804,
      "learning_rate": 2.0938897168405365e-05,
      "loss": 0.0891,
      "step": 1280
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.2711137533187866,
      "learning_rate": 2.0566318926974666e-05,
      "loss": 0.1053,
      "step": 1290
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.43644315004348755,
      "learning_rate": 2.0193740685543967e-05,
      "loss": 0.0943,
      "step": 1300
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.26273342967033386,
      "learning_rate": 1.9821162444113264e-05,
      "loss": 0.0891,
      "step": 1310
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3613092005252838,
      "learning_rate": 1.9448584202682565e-05,
      "loss": 0.0859,
      "step": 1320
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.28319692611694336,
      "learning_rate": 1.9076005961251863e-05,
      "loss": 0.1028,
      "step": 1330
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.3502526879310608,
      "learning_rate": 1.8703427719821164e-05,
      "loss": 0.1091,
      "step": 1340
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.38121557235717773,
      "learning_rate": 1.8330849478390464e-05,
      "loss": 0.0913,
      "step": 1350
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3590879440307617,
      "learning_rate": 1.7958271236959762e-05,
      "loss": 0.1026,
      "step": 1360
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3677429258823395,
      "learning_rate": 1.7585692995529063e-05,
      "loss": 0.1029,
      "step": 1370
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.39258405566215515,
      "learning_rate": 1.721311475409836e-05,
      "loss": 0.0845,
      "step": 1380
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3126257658004761,
      "learning_rate": 1.684053651266766e-05,
      "loss": 0.0871,
      "step": 1390
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.39704248309135437,
      "learning_rate": 1.6467958271236962e-05,
      "loss": 0.1046,
      "step": 1400
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.40129807591438293,
      "learning_rate": 1.609538002980626e-05,
      "loss": 0.0916,
      "step": 1410
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.34067338705062866,
      "learning_rate": 1.572280178837556e-05,
      "loss": 0.0945,
      "step": 1420
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.33545157313346863,
      "learning_rate": 1.5350223546944858e-05,
      "loss": 0.085,
      "step": 1430
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3960796594619751,
      "learning_rate": 1.4977645305514159e-05,
      "loss": 0.1006,
      "step": 1440
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2997826337814331,
      "learning_rate": 1.4605067064083458e-05,
      "loss": 0.0907,
      "step": 1450
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.36401575803756714,
      "learning_rate": 1.4232488822652756e-05,
      "loss": 0.0876,
      "step": 1460
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3804023265838623,
      "learning_rate": 1.3859910581222058e-05,
      "loss": 0.0971,
      "step": 1470
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3655950129032135,
      "learning_rate": 1.3487332339791356e-05,
      "loss": 0.1053,
      "step": 1480
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.3589126765727997,
      "learning_rate": 1.3114754098360657e-05,
      "loss": 0.0922,
      "step": 1490
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.2936452031135559,
      "learning_rate": 1.2742175856929956e-05,
      "loss": 0.0985,
      "step": 1500
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3776634633541107,
      "learning_rate": 1.2369597615499255e-05,
      "loss": 0.1074,
      "step": 1510
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.42304089665412903,
      "learning_rate": 1.1997019374068554e-05,
      "loss": 0.0917,
      "step": 1520
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3699314296245575,
      "learning_rate": 1.1624441132637855e-05,
      "loss": 0.0857,
      "step": 1530
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.34808000922203064,
      "learning_rate": 1.1251862891207155e-05,
      "loss": 0.104,
      "step": 1540
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4983136057853699,
      "learning_rate": 1.0879284649776454e-05,
      "loss": 0.107,
      "step": 1550
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.28588035702705383,
      "learning_rate": 1.0506706408345753e-05,
      "loss": 0.0985,
      "step": 1560
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3353995382785797,
      "learning_rate": 1.0134128166915052e-05,
      "loss": 0.0788,
      "step": 1570
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.34714239835739136,
      "learning_rate": 9.761549925484351e-06,
      "loss": 0.0986,
      "step": 1580
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.29150286316871643,
      "learning_rate": 9.388971684053652e-06,
      "loss": 0.0845,
      "step": 1590
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3758397698402405,
      "learning_rate": 9.016393442622952e-06,
      "loss": 0.1,
      "step": 1600
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.35553014278411865,
      "learning_rate": 8.64381520119225e-06,
      "loss": 0.0917,
      "step": 1610
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3402419984340668,
      "learning_rate": 8.27123695976155e-06,
      "loss": 0.0957,
      "step": 1620
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3583015203475952,
      "learning_rate": 7.89865871833085e-06,
      "loss": 0.0794,
      "step": 1630
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.34856680035591125,
      "learning_rate": 7.526080476900149e-06,
      "loss": 0.0989,
      "step": 1640
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3892934322357178,
      "learning_rate": 7.153502235469449e-06,
      "loss": 0.0946,
      "step": 1650
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.32203277945518494,
      "learning_rate": 6.7809239940387485e-06,
      "loss": 0.1017,
      "step": 1660
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.32331162691116333,
      "learning_rate": 6.408345752608049e-06,
      "loss": 0.0983,
      "step": 1670
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.382542222738266,
      "learning_rate": 6.035767511177348e-06,
      "loss": 0.0911,
      "step": 1680
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.31763359904289246,
      "learning_rate": 5.663189269746647e-06,
      "loss": 0.0949,
      "step": 1690
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3692617118358612,
      "learning_rate": 5.290611028315946e-06,
      "loss": 0.0851,
      "step": 1700
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3118506371974945,
      "learning_rate": 4.918032786885246e-06,
      "loss": 0.0839,
      "step": 1710
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3968191146850586,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 0.0888,
      "step": 1720
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.37604397535324097,
      "learning_rate": 4.172876304023846e-06,
      "loss": 0.1036,
      "step": 1730
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3344436287879944,
      "learning_rate": 3.800298062593145e-06,
      "loss": 0.0958,
      "step": 1740
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.4736347496509552,
      "learning_rate": 3.4277198211624444e-06,
      "loss": 0.0823,
      "step": 1750
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3162100613117218,
      "learning_rate": 3.0551415797317436e-06,
      "loss": 0.0919,
      "step": 1760
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5071600675582886,
      "learning_rate": 2.6825633383010437e-06,
      "loss": 0.0986,
      "step": 1770
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.35233747959136963,
      "learning_rate": 2.309985096870343e-06,
      "loss": 0.087,
      "step": 1780
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.31400808691978455,
      "learning_rate": 1.937406855439642e-06,
      "loss": 0.0926,
      "step": 1790
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.3153396546840668,
      "learning_rate": 1.564828614008942e-06,
      "loss": 0.0918,
      "step": 1800
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.3152306079864502,
      "learning_rate": 1.1922503725782414e-06,
      "loss": 0.0867,
      "step": 1810
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.3484465479850769,
      "learning_rate": 8.19672131147541e-07,
      "loss": 0.0853,
      "step": 1820
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.28583064675331116,
      "learning_rate": 4.470938897168406e-07,
      "loss": 0.0944,
      "step": 1830
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3637910485267639,
      "learning_rate": 7.451564828614009e-08,
      "loss": 0.1029,
      "step": 1840
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.08397004008293152,
      "eval_runtime": 54.7226,
      "eval_samples_per_second": 14.966,
      "eval_steps_per_second": 1.882,
      "step": 1842
    }
  ],
  "logging_steps": 10,
  "max_steps": 1842,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 4491318751395840.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
